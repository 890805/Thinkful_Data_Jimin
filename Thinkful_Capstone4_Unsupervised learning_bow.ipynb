{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/jiminshin/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /anaconda3/lib/python3.7/site-packages (2.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/anaconda3/lib/python3.7/site-packages/en_core_web_sm -->\n",
      "/anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(r'Ä',' ',text) \n",
    "    text = re.sub(r'Ú',' ',text)\n",
    "    text = re.sub(r'¿',' ',text)\n",
    "    text = re.sub(r'³',' ',text)\n",
    "    text = re.sub(r'==',' ',text)\n",
    "    text = re.sub(r'-=',' ', text)\n",
    "    text = re.sub(r'~~',' ',text)\n",
    "    text = text.replace(r'*',' ')\n",
    "    text = re.sub(r'&&',' ',text)\n",
    "    text = re.sub(r'íí',' ',text)\n",
    "    text = re.sub(r'\\\\X00',' ',text)\n",
    "    text = re.sub(r'x00',' ',text)\n",
    "    text = re.sub(r'ßß',' ',text)\n",
    "    text = re.sub(r'\u001a','',text)\n",
    "    text = re.sub(r'À',' ',text)\n",
    "    text = re.sub(r'Ù',' ',text)\n",
    "    text = re.sub(r\"\\(\",' ',text)\n",
    "    text = re.sub(r\"\\)\",' ',text)\n",
    "    text = re.sub(r\"\\[\",' ',text)\n",
    "    text = re.sub(r\"\\]\",' ',text)\n",
    "    text = re.sub(r'\\\"',' ',text)\n",
    "    text = re.sub(r\"\\'\",' ',text)\n",
    "    text = re.sub(r'\\;',' ',text)\n",
    "    text = re.sub(r'\\r',' ',text)\n",
    "    text = re.sub(r'  ',' ',text)\n",
    "    text = re.sub(r'\\d+', '',text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "ball = gutenberg.raw('chesterton-ball.txt')\n",
    "stories = gutenberg.raw('bryant-stories.txt')\n",
    "parents = gutenberg.raw('edgeworth-parents.txt')\n",
    "moby_dick = gutenberg.raw('melville-moby_dick.txt')\n",
    "paradise = gutenberg.raw('milton-paradise.txt')\n",
    "ceasar = gutenberg.raw('shakespeare-caesar.txt')\n",
    "leaves = gutenberg.raw('whitman-leaves.txt')\n",
    "busterbrown = gutenberg.raw('burgess-busterbrown.txt')\n",
    "\n",
    "\n",
    "alice = text_cleaner(alice[:int(len(alice)/10)])\n",
    "persuasion = text_cleaner(persuasion[:int(len(alice)/10)])\n",
    "ball = text_cleaner(ball[:int(len(alice)/10)])\n",
    "stories = text_cleaner(stories[:int(len(alice)/10)])\n",
    "parents = text_cleaner(parents[:int(len(alice)/10)])\n",
    "moby_dick = text_cleaner(moby_dick[:int(len(alice)/10)])\n",
    "paradise = text_cleaner(paradise[:int(len(alice)/10)])\n",
    "ceasar = text_cleaner(ceasar[:int(len(alice)/10)])\n",
    "leaves = text_cleaner(leaves[:int(len(alice)/10)])\n",
    "busterbrown = text_cleaner(busterbrown[:int(len(alice)/10)])\n",
    "\n",
    "\n",
    "# Now we'll match and remove chapter headings.\n",
    "persuasion = re.sub(r'chapter \\d', '', persuasion)\n",
    "alice = re.sub(r'chapter \\d', '', alice)\n",
    "ball = re.sub(r'chapter \\d', '', ball)\n",
    "stories = re.sub(r'chapter \\d', '', stories)\n",
    "parents = re.sub(r'chapter \\d', '', parents)\n",
    "moby_dick = re.sub(r'chapter \\d', '', moby_dick)\n",
    "paradise = re.sub(r'chapter \\d', '', paradise)\n",
    "ceasar = re.sub(r'chapter \\d', '', ceasar)\n",
    "leaves = re.sub(r'chapter \\d', '', leaves)\n",
    "busterbrown = re.sub(r'chapter \\d', '', busterbrown)\n",
    "\n",
    "# Remove Chapter Heading\n",
    "persuasion = re.sub(r'chapter .', '', persuasion)\n",
    "alice = re.sub(r'chapter .', '', alice)\n",
    "ball = re.sub(r'chapter .', '', ball)\n",
    "stories = re.sub(r'chapter .', '', stories)\n",
    "parents = re.sub(r'chapter .', '', parents)\n",
    "moby_dick = re.sub(r'chapter .', '', moby_dick)\n",
    "paradise = re.sub(r'chapter .', '', paradise)\n",
    "ceasar = re.sub(r'chapter .', '', ceasar)\n",
    "leaves = re.sub(r'chapter .', '', leaves)\n",
    "busterbrown = re.sub(r'chapter .', '', busterbrown)\n",
    "\n",
    "persuasion = persuasion.replace('\\n','')\n",
    "alice = alice.replace('\\n','')\n",
    "ball = ball.replace('\\n','')\n",
    "stories = stories.replace('\\n','')\n",
    "parents = parents.replace('\\n','')\n",
    "moby_dick = moby_dick.replace('\\n','')\n",
    "paradise = paradise.replace('\\n','')\n",
    "ceasar = ceasar.replace('\\n','')\n",
    "leaves = leaves.replace('\\n','')\n",
    "busterbrown = busterbrown.replace('\\n','')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "persuasion_doc = nlp(persuasion)\n",
    "alice_doc = nlp(alice)\n",
    "ball_doc = nlp(ball)\n",
    "stories_doc = nlp(stories)\n",
    "parents_doc = nlp(parents)\n",
    "moby_dick_doc = nlp(moby_dick)\n",
    "paradise_doc = nlp(paradise)\n",
    "ceasar_doc = nlp(ceasar)\n",
    "leaves_doc = nlp(leaves)\n",
    "busterbrown_doc = nlp(busterbrown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(alices, adventures, in, wonderland, by, lewis...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(she, had, peeped, into, thebook, her, sister,...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(but, it, had, no, pictures, or, conversations...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(and, what, is, the, use, of, a, book, thought...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(orconversationso)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (alices, adventures, in, wonderland, by, lewis...  Carroll\n",
       "1  (she, had, peeped, into, thebook, her, sister,...  Carroll\n",
       "2  (but, it, had, no, pictures, or, conversations...  Carroll\n",
       "3  (and, what, is, the, use, of, a, book, thought...  Carroll\n",
       "4                                 (orconversationso)  Carroll"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "ball_sents = [[sent, \"Esterton\"] for sent in ball_doc.sents]\n",
    "stories_sents = [[sent, \"Bryant\"] for sent in stories_doc.sents]\n",
    "parents_sents = [[sent, \"Edgeworth\"] for sent in parents_doc.sents]\n",
    "moby_dick_sents = [[sent, \"Melville\"] for sent in moby_dick_doc.sents]\n",
    "paradise_sents = [[sent, \"Milton\"] for sent in paradise_doc.sents]\n",
    "ceasar_sents = [[sent, \"Shakespeare\"] for sent in ceasar_doc.sents]\n",
    "leaves_sents = [[sent, \"Whitman\"] for sent in leaves_doc.sents]\n",
    "busterbrown_sents = [[sent, \"Burgess\"] for sent in busterbrown_doc.sents]\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents + ball_sents + stories_sents + parents_sents + moby_dick_sents + paradise_sents+ ceasar_sents + leaves_sents + busterbrown_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "ballwords = bag_of_words(ball_doc)\n",
    "storieswords = bag_of_words(stories_doc)\n",
    "parentswords = bag_of_words(parents_doc)\n",
    "moby_dickwords = bag_of_words(moby_dick_doc)\n",
    "paradisewords = bag_of_words(paradise_doc)\n",
    "ceasarwords = bag_of_words(ceasar_doc)\n",
    "leaveswords = bag_of_words(leaves_doc)\n",
    "busterbrownwords = bag_of_words(busterbrown_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords+ ballwords + storieswords + parentswords + moby_dickwords + paradisewords+ ceasarwords + leaveswords + busterbrownwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inventedthe</th>\n",
       "      <th>divinethe</th>\n",
       "      <th>wasnow</th>\n",
       "      <th>eternal</th>\n",
       "      <th>certaine</th>\n",
       "      <th>world</th>\n",
       "      <th>tragedie</th>\n",
       "      <th>complete</th>\n",
       "      <th>worthy</th>\n",
       "      <th>tree</th>\n",
       "      <th>...</th>\n",
       "      <th>inspire</th>\n",
       "      <th>passage</th>\n",
       "      <th>swedish</th>\n",
       "      <th>creation</th>\n",
       "      <th>herselfrather</th>\n",
       "      <th>eye</th>\n",
       "      <th>woe</th>\n",
       "      <th>story</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(alices, adventures, in, wonderland, by, lewis...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(she, had, peeped, into, thebook, her, sister,...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(but, it, had, no, pictures, or, conversations...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(and, what, is, the, use, of, a, book, thought...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(orconversationso)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  inventedthe divinethe wasnow eternal certaine world tragedie complete  \\\n",
       "0           0         0      0       0        0     0        0        0   \n",
       "1           0         0      0       0        0     0        0        0   \n",
       "2           0         0      0       0        0     0        0        0   \n",
       "3           0         0      0       0        0     0        0        0   \n",
       "4           0         0      0       0        0     0        0        0   \n",
       "\n",
       "  worthy tree     ...     inspire passage swedish creation herselfrather eye  \\\n",
       "0      0    0     ...           0       0       0        0             0   0   \n",
       "1      0    0     ...           0       0       0        0             0   0   \n",
       "2      0    0     ...           0       0       0        0             0   0   \n",
       "3      0    0     ...           0       0       0        0             0   0   \n",
       "4      0    0     ...           0       0       0        0             0   0   \n",
       "\n",
       "  woe story                                      text_sentence text_source  \n",
       "0   0     0  (alices, adventures, in, wonderland, by, lewis...     Carroll  \n",
       "1   0     0  (she, had, peeped, into, thebook, her, sister,...     Carroll  \n",
       "2   0     0  (but, it, had, no, pictures, or, conversations...     Carroll  \n",
       "3   0     0  (and, what, is, the, use, of, a, book, thought...     Carroll  \n",
       "4   0     0                                 (orconversationso)     Carroll  \n",
       "\n",
       "[5 rows x 1231 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9775280898876404\n",
      "\n",
      "Test set score: 0.7166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 1229) (178,)\n",
      "Training set score: 0.9157303370786517\n",
      "\n",
      "Test set score: 0.6833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2') # No need to specify l2 as it's the default. But we put it for demonstration.\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9831460674157303\n",
      "\n",
      "Test set score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=4, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=4)\n",
    "pca.fit(X)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaMatrix = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9213483146067416\n",
      "\n",
      "Test set score: 0.5333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = pcaMatrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 4) (178,)\n",
      "Training set score: 0.6235955056179775\n",
      "\n",
      "Test set score: 0.6166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2') # No need to specify l2 as it's the default. But we put it for demonstration.\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9550561797752809\n",
      "\n",
      "Test set score: 0.5166666666666667\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
